# 常用的视觉编码器
## 1. CNN系列视觉编码器
### 1.1 ResNet家族
* ResNet-50/101/152：引入残差连接，解决深层网络退化问题
* ResNeXt：在ResNet基础上增加了组卷积，提高模型容量
* DenseNet：密集连接，每层都与之前所有层直接相连

### 1.2 VGG系列
* 使用小卷积核(3x3)堆叠
* 结构简单但效果良好
* 常用作特征提取的backbone

## 2. Transformer系列视觉编码器
### 2.1 ViT(Vision Transformer)
* 将图像分成 patch 后用 Transformer 处理
* 纯注意力机制架构
* 需要大规模预训练数据

### 2.2 Swin Transformer
* 引入滑动窗口注意力机制
* 支持多尺度特征提取
* 计算效率更高

### 2.3 DeiT(Data-efficient image Transformer)
* 改进的训练策略使其在较小数据集上也能良好训练
* 引入教师-学生蒸馏机制


## 3. 混合架构
* 结合CNN和Transformer的优点
* 保持CNN的归纳偏置
* 借鉴Transformer的设计理念

## 4. 预训练模型
### 4.1 MAE(Masked Autoencoders)
* 自监督学习方法
* 重建被遮挡的图像区域
* 学习通用的视觉表示

### 4.2 CLIP
* 多模态预训练模型
* 图文对比学习
* 零样本迁移能力强


